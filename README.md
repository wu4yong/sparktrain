# Spark Sreaming实时流处理项目实战
慕课网]实战课程[《Spark Sreaming实时流处理项目实战》
***

## 代码说明

* imooc_web：该项目是最后项目实战中Web项目的代码
* sparktrain：该项目是课程中所有spark项目的代码
* note：该课程的所有笔记
* OOTB环境：请关注课程页面`右上角`的`公告`

***
## 课程说明
本门课程将按照如下模块进行讲解

* 初识实时流处理：实时流处理产生背景 & 概述、离线计算和实时计算的对比、实时流处理框架对比、实时流处理架构及技术选型、实时流处理在企业中的应用
* 分布式日志收集框架Flume：Flume概述 & 架构 & 核心组件、环境部署、三个Flume案例介绍
* 分布式发布订阅消息系统Kafka：Kafka概述 & 架构 & 核心概念、环境部署、容错性测试、Java API使用、Flume和Kafka整合完成实时数据采集
* 实战环境搭建：Hadoop、HBase、Spark环境搭建
* Spark Streaming入门：Spark Streaming概述 & 应用场景、集成Spark生态系统使用、发展史、WordCount案例编写、粗粒度及细粒度两方面介绍工作原理
* Spark Streaming核心概念与编程：解读StreamingContext、DStream、Input DStream & Receivers、Transformation & Output Operations、2个案例实战分别处理socket数据集文件系统数据
* SparkStreaming进阶与案例实战：updateStateByKey算子使用、将统计结果入库、窗口函数使用、黑名单过滤、Spark Streaming整合Spark SQL操作
* Spark Streaming整合Flume：介绍Push与Pull两种方式整合之概述 & Flume Agent配置开发 & Spark Streaming应用开发 & 本地环境联调 & 服务器环境联调
* Spark Streaming整合Kafka：版本选择详解、Receiver方式与Direct方式介绍及实战
* Spark Streaming整合Flume&Kafka打造通用流处理基础：处理流程画图剖析、使用Flume采集Log4j产生日志、使用KafkaSink将Flume收集到的数据输出至Kafka、Spark Streaming消费Kafka的数据进行统计、本地测试和生产环境使用拓展
* Spark Streaming项目实战：需求分析、用户分析行为日志介绍、Python日志产生器开发、使用Flume实时收集日志信息、对接实时日志数据到Kafka、数据清洗、实现两个功能、将项目运行在服务器环境中
* 可视化实战：Spring Boot整合Eachrts完成可视化、DataV完成数据可视化
* Java拓展：使用Java开发Spark应用程序

***

欢迎关注个人公众号，不定期会推送一些大数据相关的文章
<br>
![个人公众号](https://git.imooc.com/coding-153/coding-153/raw/master/qrcode.jpg)
